<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <link rel="stylesheet" href="./style/style.css">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <link href="https://api.fontshare.com/v2/css?f[]=satoshi@400,500,501,700,701,900,901&display=swap" rel="stylesheet">
    <title>BDCC CIA 1</title>
</head>
<body>    
    <section>
        <div class="intro-wrapper">
            <div class="intro">
                <h1>BDCC CIA-1 Project</h1>
            </div>
            <div class="repo">
                <h4><a href="https://github.com/josssss07/BDCC-cia1">Github repository</a></h4>

            </div>
            <div class="topic">
                <h2>Topic: Python Performance analysis: A comparitive study with Parallelization</h2>
               
            </div>
            <div class="made-by">
                <p class ="grid-item">Class: TY BSc-IT</p>
                <p class ="grid-item">Name: Joshua Desai</p>
                <p class ="grid-item">UID: 225084</p>
                <p class ="grid-item">Subject: BDCC</p>
            </div>
        </div>
    </section>
    <section class="section1">
        <div class="overview">
            <h2>Project overview:</h2>
            <p>The study aims to evaluate the performance between the various implementation of python.
            Along with a performance analysis, we also look into how using parallel processing can have an effect on the performance and I/O operations. Lastly looking at how the parallel processing affects the BigO notation. </p>
            <p>For the performance section of the program we take a look at: </p>
            <ul>
                <li> CPython (the standard implementation of python)</li>
                <li> Cython (an implementaion which convernts python into C code)</li>
                <li> Pypy (an implementation of python with a just in time complier)</li>
                <li> Jython (an impelmentation of python that runs with the java compiler and garbage collector)</li>
            </ul>
        </div>
    </section>
   <section class="section2">
        <h2>Section 1: Performance:</h2>
        <p>In this section we will look at the performance and speed of execution of various variants of python 
        For this test, all variants had to execute a script that would solve the fibonacci series through a set number of iterations. 
        The test was timed with the use of the timeit library and each variant executed the test 3 times to get a gague of the results. </p>
        <p>Below are the performance for the tests run for CPython:</p>
        <div class="three-images">
            <img src="./site_image_files/cpython_test1.png" alt="cpython_test1" height="200" width="400">
            <img src="./site_image_files/cpython_test2.png" alt="cpython_test1"height="200" width="400">
            <img src="./site_image_files/cpython_test3.png" alt="cpython_test1"height="200" width="400">
        </div>
        <p>The following are the performance for the test runs of Pypy</p>
        <div class="three-images">
            <img src="./site_image_files/pypy3_test1.png" alt="pypy3_test1" height="200" width="400">
            <img src="./site_image_files/pypy3_test2.png" alt="pypy3_test1" height="200" width="400">
            <img src="./site_image_files/pypy3_test3.png" alt="pypy3_test1" height="200" width="400">   
        </div>
        <p>The following are the performance for the test runs of Cython</p>
        <div class="three-images">
            <img src="./py_code/Performance/Cython_performance_test/images/cython_test1.png" alt="Cython_tests" height="200" width="400">
            <img src="./py_code/Performance/Cython_performance_test/images/cython_test1.png" alt="Cython_tests" height="200" width="400">
            <img src="./py_code/Performance/Cython_performance_test/images/cython_test1.png" alt="Cython_tests" height="200" width="400">
        </div>
        <p>The following are the performance for the test runs of Jython</p>
        <div class="three-images">
            <img src="./py_code/Performance/Jython_performance_test/images/jython_test1.png" alt="jython_test_runs" height="200" width="400">
            <img src="./py_code/Performance/Jython_performance_test/images/jython_test2.png" alt="jython_test_runs" height="200" width="400">
            <img src="./py_code/Performance/Jython_performance_test/images/jython_test3.png" alt="jython_test_runs" height="200" width="400">   
        </div>

        <ol>
            <li>The standard implementaion of Python (Cpython) has the slowest performance compared to the variants of python</li>
            <li>The fastest variant was Cython, with Pypy in second and Jython in third</li>
        </ol>
        <p><b> <ul> Overall we can see the following:</ul></b> </p>
        <p>CPython is the default and most widely-used implementation of Python. It's written in C and focuses on compatibility and ease of use rather than speed.</p>
        <p>Cython allows Python code to be compiled into C, making it faster by converting Python code into highly efficient C code.
            This is particularly useful for computationally intensive tasks like mathematical operations or data processing.</p>
        <p>
            PyPy is an alternative implementation of Python with a Just-In-Time (JIT) compiler that optimizes the execution of code during runtime.
            It is generally faster than CPython for long-running programs because it compiles frequently used parts of code into machine language.
        </p>
        <p>
            Jython is a Python implementation that runs on the Java Virtual Machine (JVM). It allows Python code to interoperate with Java code but isn't as fast as Cython or PyPy.
        </p>
        <p>
            Python's performance varies greatly depending on the implementation.
            If speed is critical, alternatives like Cython or PyPy should be considered instead of CPython.
            Each implementation has trade-offs, such as compatibility, ease of use, and integration with other systems.
        </p>
        <h4>Example:</h4>
        <p>
            Imagine you're processing a large dataset with Python. Using:
        </p>
        <ul>
            <li>CPython: Execution will be slower but fully compatible with most Python libraries.
            </li>
            <li>
                Cython: You can achieve a significant speed-up by compiling your data processing functions into C code.
            </li>
            <li>
                PyPy: Speeds up the execution if you're running the script repeatedly with many iterations.
            </li>
        </ul>
        <p>The main choice of implementaion depends on the usecase and the performance requirement and need</p>
        <!-- <h3>Some performance charts </h3>
        <canvas id="performanceChart"></canvas> -->
    </section >

    <section class="section3">
        <h2>Section 2: Parallelization, Multithreading, Profiling and Cuda </h2>
        <h5>Theory:</h5>
        <div>
            <p>In this section we will look at what is Parallelization, multithreading, some usecases with an example and what is cuda</p>
            <p>
                Parallelization is the process of splitting tasks into smaller sub-tasks and running them simultaneously across multiple CPUs or cores.
                It is typically achieved using the multiprocessing module in Python, which creates multiple processes, each with its own memory space.
                Suitable for CPU-bound tasks (e.g., numerical computations, simulations) because multiple processes can run on separate cores without being restricted by the Global Interpreter Lock (GIL).
            </p>
            <p>
                Multithreading allows multiple threads to run concurrently within a single process, sharing the same memory space.
                Python's threading module is used for multithreading, but threads are limited by the GIL, so they can't truly run in parallel for CPU-bound tasks.
                Best suited for I/O-bound tasks (e.g., reading files, making API calls), where the program waits for external resources.
            </p>
            <p>

Profiling:
Profiling is the process of analyzing the performance of a program to identify bottlenecks, inefficient code, and resource usage (CPU, memory, I/O, etc.).
It helps optimize the program by showing where the most time or resources are spent.
Implementation in Python:

Tools like cProfile, line_profiler, or third-party libraries such as Py-Spy are commonly used.
            </p>
            <p>
                CUDA:
                CUDA (Compute Unified Device Architecture) is a parallel computing platform and API by NVIDIA for utilizing GPUs (Graphics Processing Units) for general-purpose computing.
                It allows Python (or other languages) to offload intensive computations to the GPU, leveraging thousands of GPU cores for faster performance.
                Implementation in Python:
                            
                Python libraries like PyCUDA, CuPy, or Numba are used to write and execute CUDA kernels.
                GPU-accelerated libraries such as TensorFlow or PyTorch often use CUDA under the hood.
                Key Difference:
                Profiling: Focuses on measuring and optimizing the performance of a program.
                CUDA: A platform for accelerating computations using NVIDIA GPUs.
            </p>
            <p>
                Where CUDA Can Be Used:
                CUDA is primarily used in areas where computational tasks are highly parallelizable. Examples include:

                Machine Learning and Deep Learning:

                Training neural networks (e.g., TensorFlow, PyTorch).
                Speeding up tasks like matrix multiplications and backpropagation.
                Scientific Simulations:

                Weather forecasting, molecular dynamics, or particle simulations.
                Image and Video Processing:

                Real-time object detection, video encoding/decoding, and 3D rendering.
                Financial Modeling:

                Monte Carlo simulations, risk analysis, or high-frequency trading.
                Big Data Analytics:

                Accelerating database queries and data transformations (e.g., RAPIDS for GPU-accelerated data analysis).
                Cryptography:

                Hash computations, password cracking, or blockchain mining.
                Real-World Scenario: Performance Gain with CUDA
                Task: Matrix Multiplication (common in machine learning and numerical simulations).
                We compare the performance of matrix multiplication using CPU (NumPy) and GPU (CUDA via CuPy).
            </p>

            <p>
                Looking at multithreading in depth, we can use the example of merege sort and parallel merge sort: 
            </p>

            <p>
                Parallel Merge Sort is an enhancement of the traditional Merge Sort algorithm that leverages parallel computing to divide the workload across multiple threads or processes. This allows different parts of the array to be sorted simultaneously, making it faster for large datasets when executed on multi-core processors.
            </p>
            <p>
                Why is parallel merge sort faster than the traditional merge sort?
            </p>
            <p>
                Divide-and-Conquer in Parallel:

Traditional Merge Sort divides the array into smaller subarrays recursively and processes them sequentially.
Parallel Merge Sort assigns different threads or processes to sort each subarray simultaneously, reducing the time spent in the sorting phase.
Parallel Merging:

The merging phase can also be parallelized by dividing the merging process among threads, further optimizing performance.
Utilization of Multi-core Processors:

Parallel Merge Sort takes advantage of modern multi-core CPUs, where each core can handle part of the computation independently.
            </p>

            <p>Parallel merge sort vs Regular merege sort:</p>

            <canvas id="mergeSortChart"></canvas>

            <P>Paralle martix multipliation vs sequential</P>

            <canvas id="matrixMultiplicationChart"></canvas>
             
        </div>
    </section>


    <script>
        // Chart Data
        const data = {
            labels: ['10,000', '100,000', '1,000,000', '10,000,000'], // Array sizes
            datasets: [
                {
                    label: 'Sequential Merge Sort (seconds)',
                    data: [0.03, 0.30, 3.5, 40], // Timings for sequential
                    backgroundColor: 'rgba(255, 99, 132, 0.6)', // Red color
                    borderColor: 'rgba(255, 99, 132, 1)',
                    borderWidth: 1
                },
                {
                    label: 'Parallel Merge Sort (seconds)',
                    data: [0.04, 0.18, 1.2, 14], // Timings for parallel
                    backgroundColor: 'rgba(54, 162, 235, 0.6)', // Blue color
                    borderColor: 'rgba(54, 162, 235, 1)',
                    borderWidth: 1
                }
            ]
        };

        // Chart Options
        const options = {
            responsive: true,
            plugins: {
                legend: {
                    position: 'top', // Position of the legend
                },
                title: {
                    display: true,
                    text: 'Comparison of Merge Sort Algorithms'
                }
            },
            scales: {
                y: {
                    beginAtZero: true,
                    title: {
                        display: true,
                        text: 'Time (seconds)'
                    }
                },
                x: {
                    title: {
                        display: true,
                        text: 'Array Size'
                    }
                }
            }
        };

        // Initialize Chart.js
        const ctx = document.getElementById('mergeSortChart').getContext('2d');
        const mergeSortChart = new Chart(ctx, {
            type: 'bar', // Bar chart type
            data: data,
            options: options
        });
    </script>
    

    <script>
        // Chart Data
        const data2 = {
            labels: ['100 x 100', '500 x 500', '1000 x 1000', '2000 x 2000'], // Matrix sizes
            datasets: [
                {
                    label: 'Sequential Processing (seconds)',
                    data: [0.02, 0.35, 3.0, 22.0], // Timings for sequential
                    backgroundColor: 'rgba(255, 159, 64, 0.6)', // Orange color
                    borderColor: 'rgba(255, 159, 64, 1)',
                    borderWidth: 1
                },
                {
                    label: 'Parallel Processing (seconds)',
                    data: [0.03, 0.20, 1.2, 8.5], // Timings for parallel
                    backgroundColor: 'rgba(75, 192, 192, 0.6)', // Teal color
                    borderColor: 'rgba(75, 192, 192, 1)',
                    borderWidth: 1
                }
            ]
        };

        // Chart Options
        const options2 = {
            responsive: true,
            plugins: {
                legend: {
                    position: 'top', // Position of the legend
                },
                title: {
                    display: true,
                    text: 'Comparison of Matrix Multiplication Times'
                }
            },
            scales: {
                y: {
                    beginAtZero: true,
                    title: {
                        display: true,
                        text: 'Time (seconds)'
                    }
                },
                x: {
                    title: {
                        display: true,
                        text: 'Matrix Size'
                    }
                }
            }
        };

        // Initialize Chart.js
        const ctx2 = document.getElementById('matrixMultiplicationChart').getContext('2d');
        const matrixMultiplicationChart = new Chart(ctx2, {
            type: 'bar', // Bar chart type
            data: data2,
            options: options2
        });
    </script>


<script>
    // Data
    const complexities = [20, 25, 30];
    const meanTimes = [0.0064, 0.065, 0.7461];
    const medianTimes = [0.0064, 0.0646, 0.7459];
    const stdDeviations = [0.0002, 0.0025, 0.006];

    // Chart configuration
    const data3 = {
      labels: complexities,
      datasets: [
        {
          label: 'Mean Time (seconds)',
          data: meanTimes,
          borderColor: 'rgba(75, 192, 192, 1)',
          backgroundColor: 'rgba(75, 192, 192, 0.2)',
          borderWidth: 2,
          fill: true,
        },
        {
          label: 'Median Time (seconds)',
          data: medianTimes,
          borderColor: 'rgba(153, 102, 255, 1)',
          backgroundColor: 'rgba(153, 102, 255, 0.2)',
          borderWidth: 2,
          fill: true,
        },
        {
          label: 'Standard Deviation (seconds)',
          data: stdDeviations,
          borderColor: 'rgba(255, 159, 64, 1)',
          backgroundColor: 'rgba(255, 159, 64, 0.2)',
          borderWidth: 2,
          fill: true,
        }
      ]
    };

    const confi = {
      type: 'line',
      data: data,
      options: {
        responsive: true,
        plugins: {
          title: {
            display: true,
            text: 'Performance Metrics vs. Complexity',
            font: {
              size: 18
            }
          },
        },
        scales: {
          x: {
            title: {
              display: true,
              text: 'Complexity',
              font: {
                size: 14
              }
            }
          },
          y: {
            title: {
              display: true,
              text: 'Time (seconds)',
              font: {
                size: 14
              }
            },
            beginAtZero: true
          }
        }
      }
    };

    // Render the chart
    const ctx3 = document.getElementById('performanceChart').getContext('2d');
    new Chart(ctx3, config);
  </script>
</body>
</html>